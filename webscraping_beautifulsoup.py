# -*- coding: utf-8 -*-
"""webscraping beautifulsoup.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Sb_oqAuLv2CAqJ7WeUH-0jaWlXIDF_RH
"""

from bs4 import BeautifulSoup
import requests
import pandas as pd

url1 = 'https://www.scrapethissite.com/pages/forms/?page_num=1'

page1 = requests.get(url1)
print(page1)

soup1 = BeautifulSoup(page1.text,'html')
soup1.prettify()

header = soup1.find('h1').text.strip()
print(header)

paragraph = soup1.find('p', class_ = 'lead').text.strip()
print(paragraph)

data_r = soup1.find('a', class_ = "data-attribution").text.strip()
print(data_r)

table1 = soup1.find_all('th')
print(table1)

hockey_table1 = [header1.text.strip() for header1 in table1]
print(hockey_table1)

df1 = pd.DataFrame(columns = hockey_table1)

print(df1)

team_data1 = soup1.find_all('tr')
print(team_data1)

for row1 in team_data1[1:]:
  row_data1 = row1.find_all('td')
  print(row_data1)
  team_row_data1 = [data1.text.strip()for data1 in row_data1]
  print(team_row_data1)
  length1 = len(df1)
  df1.loc[length1] = team_row_data1

print(df1)



url2 = 'https://www.scrapethissite.com/pages/forms/?page_num=2'

page2 = requests.get(url2)
print(page2)

soup2 = BeautifulSoup(page2.text, 'html')
print(soup2.prettify())

table2 = soup2.find_all('th')
print(table2)

hockey_table2 = [ table_title2.text.strip() for table_title2 in table2]
print(hockey_table2)

df2 = pd.DataFrame(columns = hockey_table2)
print(df2)

team_data2 = soup2.find_all('tr')
print(team_data2)

for row2 in team_data2[1:]:
  row_data2 = row2.find_all('td')
  print(row_data2)
  team_row_data2 = [data2.text.strip()for data2 in row_data2]
  print(team_row_data2)
  length2 = len(df2)
  df2.loc[length2] = team_row_data2

print(df2)



url3 = 'https://www.scrapethissite.com/pages/forms/?page_num=3'

page3 = requests.get(url3)
print(page3)

soup3 = BeautifulSoup(page3.text, 'html')
print(soup3.prettify())

table3 = soup3.find_all('th')
print(table3)

hockey_table3 = [title3.text.strip()for title3 in table3]
print(hockey_table3)

df3 = pd.DataFrame(columns = hockey_table3)

print(df3)

team_data3 = soup3.find_all('tr')
print(team_data3)

for row3 in team_data3[1:]:
  row_data3 = row3.find_all('td')
  print(row_data3)
  team_row_data3 = [data3.text.strip()for data3 in row_data3]
  print(team_row_data3)
  length3 = len(df3)
  df3.loc[length3] = team_row_data3

print(df3)



url4 = 'https://www.scrapethissite.com/pages/forms/?page_num=4'

page4 = requests.get(url4)
print(page4)

soup4 = BeautifulSoup(page4.text, 'html')
print(soup4.prettify())

table4 = soup4.find_all('th')
print(table4)

hockey_table4 = [title4.text.strip()for title4 in table4]
print(hockey_table4)

df4 = pd.DataFrame(columns = hockey_table4)

print(df4)

team_data4 = soup4.find_all('tr')
print(team_data4)

for row4 in team_data4[1:]:
  row_data4 = row4.find_all('td')
  print(row_data4)
  team_row_data4 = [data4.text.strip() for data4 in row_data4]
  print(team_row_data4)
  length4 = len(df4)
  df4.loc[length4] = team_row_data4

print(df4)



url5 = 'https://www.scrapethissite.com/pages/forms/?page_num=5'

page5 = requests.get(url5)
print(page5)

soup5 = BeautifulSoup(page5.text, 'html')
print(soup5.prettify())

table5 = soup5.find_all('th')
print(table5)

hockey_table5 = [title5.text.strip() for title5 in table5]
print(hockey_table5)

df5 = pd.DataFrame(columns = hockey_table5)

print(df5)

team_data5 = soup5.find_all('tr')
print(team_data5)

for row5 in team_data5[1:]:
  row_data5 = row5.find_all('td')
  print(row_data5)
  team_row_data5 = [data5.text.strip()for data5 in row_data5]
  print(team_row_data5)
  length5 = len(df5)
  df5.loc[length5] = team_row_data5

print(df5)



url6 = 'https://www.scrapethissite.com/pages/forms/?page_num=6'

page6 = requests.get(url6)
print(page6)

soup6 = BeautifulSoup(page6.text,'html')
print(soup6.prettify())

table6 = soup6.find_all('th')
print(table6)

hockey_table6 = []
for title6 in table6:
  hockey_table6.append(title6.text.strip())

print(hockey_table6)

df6 = pd.DataFrame(columns = hockey_table6)

print(df6)

team_data6 = soup6.find_all('tr')
print(team_data6)

for row6 in team_data6[1:]:
  row_data6 = row6.find_all('td')
  print(row_data6)
  team_row_data6 = []
  for data6 in row_data6:
    team_row_data6.append(data6.text.strip())
    print(team_row_data6)
  length6 = len(df6)
  df6.loc[length6] = team_row_data6

print(df6)



url7 = 'https://www.scrapethissite.com/pages/forms/?page_num=7'

page7 = requests.get(url7)
print(page7)

soup7 = BeautifulSoup(page7.text,'html')
print(soup7.prettify())

table7 = soup7.find_all('th')
print(table7)

hockey_table7 = [title7.text.strip() for title7 in table7]

print(hockey_table7)

df7 = pd.DataFrame(columns = hockey_table7)

print(df7)

team_data7 = soup7.find_all('tr')
print(team_data7)

for row7 in team_data7[1:]:
  row7_data = row7.find_all('td')
  print(row7_data)
  team_row7_data = [data7.text.strip() for data7 in row7_data]
  print(team_row7_data)
  length7 = len(df7)
  df7.loc[length7] = team_row7_data

print(df7)








